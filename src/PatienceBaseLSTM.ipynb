{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270b9b40-830d-45cf-ba74-c96a6ceb6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2   \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import RandomSearch, HyperModel, Hyperband, HyperParameters\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from DataEncoder import encode_pad_event, encode_pad_sequence, encode_y\n",
    "from BaseLSTMIm import BaseLSTMModel,print_best_hp\n",
    "from utils import plot_training_history_LSTMim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc33c0e1-3f2c-498d-b1e1-ac11f2cc6eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = pd.read_csv(\"D:/Research in UAE/sequence/output/Event_Feature_pro.csv\")\n",
    "sequence = pd.read_csv(\"D:/Research in UAE/sequence/output/Sequence_Feature_pro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42c468e-a085-420f-81b8-7b8407f89824",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = sequence.result\n",
    "y_encode = encode_y(y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0a6672-59b9-42be-a400-075751571421",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_event = ['Activity_verb', 'Activity_Dec', 'Resource', 'outcome', \"stopcode\"]\n",
    "num_col_event = ['net_promotor_score', 'creditscore', 'rate_charged', 'duration']\n",
    "case_index = 'Case ID'\n",
    "\n",
    "event_encode = encode_pad_event(event, cat_col_event, num_col_event, case_index, cat_mask = True, num_mask = True, eos = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a086ae1-ee2a-48f9-99c7-ffc9250c56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_seq = ['plan']\n",
    "num_col_seq = ['age', 'coverage_numeric', 'length_of_stay']\n",
    "sequence_encode = encode_pad_sequence(sequence, cat_col_seq, num_col_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3dbda86-8221-41a7-89a2-6c5f34eda9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape (sequence_length, number_of_features)\n",
    "event_input_shape = (event_encode.shape[1], event_encode.shape[2])\n",
    "\n",
    "# Define the number of classes \n",
    "num_classes = y_encode.shape[1]\n",
    "\n",
    "# number of sequence features\n",
    "num_sequence_features = sequence_encode.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8f98e92-94b3-41e8-af02-e748b190d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include batch size as a hyperparameter to be tuned\n",
    "hp_b = HyperParameters()\n",
    "batch_size = hp_b.Choice('batch_size', values=[16, 32, 64, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7326642a-c79e-436c-8ab4-1280e1655d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split indices for train and test\n",
    "train_indices, test_indices = train_test_split(np.arange(len(y_encode)), test_size=0.2, stratify=y_encode, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "train_event_features = event_encode[train_indices]\n",
    "test_event_features = event_encode[test_indices]\n",
    "\n",
    "train_sequence_features = sequence_encode[train_indices]\n",
    "test_sequence_features = sequence_encode[test_indices]\n",
    "\n",
    "train_y = y_encode[train_indices]\n",
    "test_y = y_encode[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf2bda7-b778-42a5-bd3c-9466fdea78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the hypermodel\n",
    "hypermodel = BaseLSTMModel(event_input_shape=event_input_shape,\n",
    "                           num_sequence_features= num_sequence_features,\n",
    "                           num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e56108a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 32s]\n",
      "val_f1_score: 0.6499903202056885\n",
      "\n",
      "Best val_f1_score So Far: 0.8655925393104553\n",
      "Total elapsed time: 01h 30m 43s\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_f1_score',  \n",
    "                               mode='max',\n",
    "                               patience=5, \n",
    "                               restore_best_weights=True)\n",
    "tuner_band = Hyperband(hypermodel,\n",
    "                       objective=kt.Objective(\"val_f1_score\", direction=\"max\"),\n",
    "                       max_epochs=200,\n",
    "                       factor=3,\n",
    "                       directory='hparam_tuning',\n",
    "                       overwrite=False, #if resume tuner, keep overwrite = False\n",
    "                       project_name='classfication_2levelfeature_hyperband_im',\n",
    "                       hyperparameters=hp_b)\n",
    "\n",
    "# Use the manually split data in the search\n",
    "tuner_band.search(x=[train_event_features, train_sequence_features], y=train_y, \n",
    "                  validation_data=([test_event_features, test_sequence_features], test_y), \n",
    "                  epochs=200, callbacks=[early_stopping])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps_band = tuner_band.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Get the best model\n",
    "best_model_band = tuner_band.get_best_models(num_models=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70d1f08e-cba6-4cd6-9f75-d3738cbe66a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "Confusion Matrix:\n",
      "[[ 92   0   0   0   0   0]\n",
      " [  0 174   0   0   0   0]\n",
      " [  0   0   5   0   0   0]\n",
      " [  0   0   0  21   0   0]\n",
      " [  0   4   0   0  28   0]\n",
      " [  0  45   0   0   4  55]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        92\n",
      "           1     0.7803    1.0000    0.8766       174\n",
      "           2     1.0000    1.0000    1.0000         5\n",
      "           3     1.0000    1.0000    1.0000        21\n",
      "           4     0.8750    0.8750    0.8750        32\n",
      "           5     1.0000    0.5288    0.6918       104\n",
      "\n",
      "    accuracy                         0.8762       428\n",
      "   macro avg     0.9425    0.9006    0.9072       428\n",
      "weighted avg     0.9013    0.8762    0.8656       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "y_pred_probs = best_model_band.predict([test_event_features, test_sequence_features])\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert to class indices\n",
    "y_true = np.argmax(test_y, axis=1)\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute Classification Report\n",
    "class_report = classification_report(y_true, y_pred, digits=4)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b0bcbef-633a-4168-9bde-970a3e686080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hparam_tuning\\classfication_2levelfeature_hyperband_im\\tuner0.json\n",
      "Best hyperparameters found were:\n",
      "Number of LSTM layers: 2\n",
      "  LSTM Layer 0:\n",
      "    Units: 160\n",
      "    Dropout Rate: 0.4913845777963388\n",
      "    L2 Regularization: 0.00019634218681491059\n",
      "    Batch Norm Momentum: 0.81\n",
      "    Batch Norm Epsilon: 0.00033459755475717326\n",
      "  LSTM Layer 1:\n",
      "    Units: 48\n",
      "    Dropout Rate: 0.3156053994179221\n",
      "    L2 Regularization: 0.0004419772860765411\n",
      "Number of Dense layers: 1\n",
      "  Dense Layer 0:\n",
      "    Units: 144\n",
      "    Activation: relu\n",
      "    Dropout Rate: 0.4581934322370699\n",
      "    L2 Regularization: 0.0002007819160434203\n",
      "Optimizer: rmsprop\n",
      "  Learning Rate (RMSprop): 0.0027179521580834405\n",
      "Learning Rate Schedule: piecewise_constant\n",
      "Best batch size: 32\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_f1_score',  \n",
    "                               mode='max',\n",
    "                               patience=5, \n",
    "                               restore_best_weights=True)\n",
    "tuner_band = Hyperband(hypermodel,\n",
    "                       objective=kt.Objective(\"val_f1_score\", direction=\"max\"),\n",
    "                       max_epochs=200,\n",
    "                       factor=3,\n",
    "                       directory='hparam_tuning',\n",
    "                       overwrite=False, #if resume tuner, keep overwrite = False\n",
    "                       project_name='classfication_2levelfeature_hyperband_im',\n",
    "                       hyperparameters=hp_b)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps_band = tuner_band.get_best_hyperparameters(num_trials=1)[0]\n",
    "print_best_hp(best_hps_band)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cddfa84-a7d6-46b9-88a5-2cd22e9137a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - f1_score: 0.8175 - loss: 0.4673 - val_f1_score: 0.8610 - val_loss: 0.4081\n",
      "Epoch 2/200\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - f1_score: 0.8296 - loss: 0.4098 - val_f1_score: 0.8436 - val_loss: 0.4136\n",
      "Epoch 3/200\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - f1_score: 0.8407 - loss: 0.4060 - val_f1_score: 0.8716 - val_loss: 0.3458\n",
      "Epoch 4/200\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - f1_score: 0.8499 - loss: 0.3781 - val_f1_score: 0.8480 - val_loss: 0.4096\n",
      "Epoch 5/200\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - f1_score: 0.8395 - loss: 0.3952 - val_f1_score: 0.8440 - val_loss: 0.4360\n",
      "Epoch 6/200\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - f1_score: 0.8158 - loss: 0.4562 - val_f1_score: 0.8489 - val_loss: 0.3961\n",
      "Epoch 7/200\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - f1_score: 0.8294 - loss: 0.3903 - val_f1_score: 0.8494 - val_loss: 0.3911\n",
      "Epoch 8/200\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - f1_score: 0.8370 - loss: 0.4043 - val_f1_score: 0.8436 - val_loss: 0.4421\n",
      "Best epoch: 3\n",
      "Best F1 Score:  0.8715944290161133\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# alternatively, build the model with the optimal hyperparameters \n",
    "# best_model_band  = band_tuner.hypermodel.build(best_hps_band)\n",
    "history_band = best_model_band.fit(x=[train_event_features, train_sequence_features], y=train_y, \n",
    "                                   validation_data=([test_event_features, test_sequence_features], test_y), \n",
    "                                   epochs=200, batch_size=best_hps_band.get('batch_size'), callbacks=[early_stopping])\n",
    "\n",
    "#print(history_band.history.keys())  \n",
    "\n",
    "val_acc_per_epoch_band = history_band.history['val_f1_score']\n",
    "best_epoch_band = val_acc_per_epoch_band.index(max(val_acc_per_epoch_band)) + 1\n",
    "print('Best epoch: %d' % (best_epoch_band,))\n",
    "print('Best F1 Score: ', max(val_acc_per_epoch_band))\n",
    "# Evaluate the best model\n",
    "#loss, accuracy = best_model_band.evaluate([event_encode, sequence_encode],y_encode)\n",
    "#print('Test accuracy:', accuracy)\n",
    "\n",
    "plot_training_history_LSTMim(history_band.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "094394b6-e125-406e-aece-f72436b39355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hparam_tuning\\classfication_2levelfeatures_rand\\tuner0.json\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "128               |16                |batch_size\n",
      "3                 |2                 |num_lstm_layers\n",
      "240               |48                |lstm_units_l0\n",
      "3.1668e-05        |0.00049681        |l2_reg_l0\n",
      "True              |True              |use_batch_norm_l0\n",
      "0.4403            |0.34583           |dropout_l0\n",
      "2                 |3                 |num_dense_layers\n",
      "16                |144               |dense_units_0\n",
      "0.0006438         |1.244e-05         |l2_dense_0\n",
      "tanh              |softmax           |dense_activation_0\n",
      "0.54881           |0.1019            |dropout_dense_0\n",
      "inverse_time      |polynomial        |lr_schedule_type\n",
      "0.00017534        |0.00077456        |init_lr\n",
      "sgd               |adam              |optimizer\n",
      "0.88              |0.89              |adam_beta_1\n",
      "0.993             |0.991             |adam_beta_2\n",
      "0.11              |0.01              |batch_norm_momentum_0\n",
      "0.00041091        |1e-05             |batch_norm_epsilon_0\n",
      "32                |16                |lstm_units_l1\n",
      "1.2254e-05        |1e-05             |l2_reg_l1\n",
      "True              |False             |use_batch_norm_l1\n",
      "0.20547           |0.2               |dropout_l1\n",
      "208               |16                |dense_units_1\n",
      "0.0014767         |1e-05             |l2_dense_1\n",
      "relu              |relu              |dense_activation_1\n",
      "0.27326           |0.1               |dropout_dense_1\n",
      "80                |16                |dense_units_2\n",
      "5.1916e-05        |1e-05             |l2_dense_2\n",
      "softmax           |relu              |dense_activation_2\n",
      "0.44321           |0.1               |dropout_dense_2\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.0439 - loss: 2.2599 - val_accuracy: 0.0280 - val_loss: 2.1961\n",
      "Epoch 2/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0267 - loss: 2.2533 - val_accuracy: 0.0280 - val_loss: 2.1772\n",
      "Epoch 3/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0471 - loss: 2.2433 - val_accuracy: 0.0373 - val_loss: 2.1647\n",
      "Epoch 4/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0511 - loss: 2.2273 - val_accuracy: 0.0326 - val_loss: 2.1535\n",
      "Epoch 5/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0575 - loss: 2.2129 - val_accuracy: 0.0443 - val_loss: 2.1343\n",
      "Epoch 6/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0706 - loss: 2.2019 - val_accuracy: 0.1096 - val_loss: 2.1239\n",
      "Epoch 7/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0745 - loss: 2.1744 - val_accuracy: 0.0932 - val_loss: 2.1072\n",
      "Epoch 8/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0997 - loss: 2.1693 - val_accuracy: 0.2145 - val_loss: 2.1004\n",
      "Epoch 9/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1040 - loss: 2.1418 - val_accuracy: 0.2424 - val_loss: 2.0867\n",
      "Epoch 10/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1225 - loss: 2.1486 - val_accuracy: 0.3869 - val_loss: 2.0763\n",
      "Epoch 11/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1428 - loss: 2.1292 - val_accuracy: 0.3706 - val_loss: 2.0625\n",
      "Epoch 12/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1493 - loss: 2.1266 - val_accuracy: 0.4103 - val_loss: 2.0571\n",
      "Epoch 13/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1581 - loss: 2.1103 - val_accuracy: 0.4103 - val_loss: 2.0487\n",
      "Epoch 14/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1872 - loss: 2.0966 - val_accuracy: 0.4126 - val_loss: 2.0399\n",
      "Epoch 15/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2101 - loss: 2.0848 - val_accuracy: 0.4219 - val_loss: 2.0231\n",
      "Epoch 16/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2094 - loss: 2.0719 - val_accuracy: 0.4196 - val_loss: 2.0146\n",
      "Epoch 17/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2321 - loss: 2.0673 - val_accuracy: 0.4266 - val_loss: 2.0004\n",
      "Epoch 18/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2518 - loss: 2.0473 - val_accuracy: 0.4172 - val_loss: 1.9980\n",
      "Epoch 19/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2683 - loss: 2.0481 - val_accuracy: 0.4219 - val_loss: 1.9899\n",
      "Epoch 20/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2846 - loss: 2.0244 - val_accuracy: 0.4172 - val_loss: 1.9751\n",
      "Epoch 21/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2919 - loss: 2.0247 - val_accuracy: 0.4149 - val_loss: 1.9685\n",
      "Epoch 22/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3305 - loss: 2.0049 - val_accuracy: 0.3986 - val_loss: 1.9562\n",
      "Epoch 23/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3122 - loss: 2.0065 - val_accuracy: 0.4103 - val_loss: 1.9517\n",
      "Epoch 24/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3398 - loss: 1.9868 - val_accuracy: 0.4149 - val_loss: 1.9379\n",
      "Epoch 25/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3500 - loss: 1.9877 - val_accuracy: 0.4149 - val_loss: 1.9261\n",
      "Epoch 26/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3359 - loss: 1.9823 - val_accuracy: 0.4242 - val_loss: 1.9135\n",
      "Epoch 27/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3880 - loss: 1.9496 - val_accuracy: 0.4056 - val_loss: 1.9106\n",
      "Epoch 28/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.3695 - loss: 1.9628 - val_accuracy: 0.4079 - val_loss: 1.9037\n",
      "Epoch 29/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4011 - loss: 1.9360 - val_accuracy: 0.3986 - val_loss: 1.8899\n",
      "Epoch 30/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3762 - loss: 1.9453 - val_accuracy: 0.4033 - val_loss: 1.8803\n",
      "Epoch 31/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3872 - loss: 1.9301 - val_accuracy: 0.4009 - val_loss: 1.8784\n",
      "Epoch 32/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3712 - loss: 1.9314 - val_accuracy: 0.4033 - val_loss: 1.8729\n",
      "Epoch 33/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4148 - loss: 1.9149 - val_accuracy: 0.4103 - val_loss: 1.8539\n",
      "Epoch 34/300\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4265 - loss: 1.8971"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# RandomSearch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tuner_rand\u001b[38;5;241m=\u001b[39m RandomSearch(\n\u001b[0;32m      3\u001b[0m     hypermodel,\n\u001b[0;32m      4\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     hyperparameters\u001b[38;5;241m=\u001b[39mhp_b\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtuner_rand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mevent_encode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_encode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_encode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Get the best models and hyperparameters after search is randed\u001b[39;00m\n\u001b[0;32m     16\u001b[0m best_model_rand \u001b[38;5;241m=\u001b[39m tuner_rand\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    242\u001b[0m     ):\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:329\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    328\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 329\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    331\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    332\u001b[0m     )\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RandomSearch\n",
    "tuner_rand= RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='hparam_tuning',\n",
    "    project_name='classfication_2levelfeatures_rand',\n",
    "    hyperparameters=hp_b\n",
    ")\n",
    "\n",
    "tuner_rand.search(x=[event_encode, sequence_encode], y = y_encode,\\\n",
    "             epochs=300, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Get the best models and hyperparameters after search is randed\n",
    "best_model_rand = tuner_rand.get_best_models(num_models=1)[0]\n",
    "best_hps_rand = tuner_rand.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Fit the best model with the optimal batch size\n",
    "best_model_rand.fit(\n",
    "    [event_encode, sequence_encode],\n",
    "    y_encode,\n",
    "    epochs=300,\n",
    "    batch_size=best_hps_rand.get('batch_size'),  # Use the best batch size found\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Evaluate the best model\n",
    "loss, accuracy = best_model_rand.evaluate([event_encode, sequence_encode], y_encode)\n",
    "print('Test accuracy:', accuracy)\n",
    "print_best_hp(best_hps_rand)\n",
    "#print_best_hp(best_hps)\n",
    "best_model_rand.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725cf584-95bd-4bc6-9d51-ee7d71e27225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680c3acc-1c03-4474-847d-51321749fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_lstm_model(event_input_shape, num_sequence_features, num_classes, lstm_units=128, dropout_rate = 0.2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create and compile an LSTM model for classification.\n",
    "    \n",
    "    Parameters:\n",
    "    - event_input_shape: Tuple representing the shape of the input data (sequence_length, number_of_features).\n",
    "    - num_sequence_features: Interger represnting the number of sequence level feature\n",
    "    - num_classes: Integer representing the number of target classes.\n",
    "    - lstm_units: Integer representing the number of units in LSTM layers.\n",
    "    - dropout_rate: Float between 0 and 1 representing the dropout rate for regularization.\n",
    "    \n",
    "    Returns:\n",
    "    - Compiled Keras model ready for training.\n",
    "    \"\"\"    \n",
    "    # Event-level input: Sequential data for LSTM processing\n",
    "    event_input = Input(shape= event_input_shape, name='event_input')\n",
    "    x = Masking(mask_value=-1.0)(event_input)\n",
    "    # LSTM layers processing event-level features\n",
    "    #lstm0_out = LSTM(lstm_units, return_sequences=True)(event_input)\n",
    "    lstm0_out = LSTM(lstm_units, return_sequences=False, kernel_regularizer=l2(0.02))(x)\n",
    "    lstm0_out = Dropout(dropout_rate)(lstm0_out)\n",
    "    #lstm1_out = LSTM(int(lstm_units / 2), return_sequences=True)(lstm0_out)\n",
    "    #lstm1_out = Dropout(dropout_rate)(lstm1_out)\n",
    "    # Additional LSTM layer\n",
    "    #lstm_out = LSTM(int(lstm_units / 2), return_sequences=False, kernel_regularizer=l2(0.02))(lstm0_out)  # Set return_sequences=False on the last LSTM layer\n",
    "    #lstm_out = Dropout(dropout_rate)(lstm_out)\n",
    "\n",
    "    # Sequence-level input: Static context features for the whole sequence\n",
    "    sequence_input = Input(shape=(num_sequence_features,), name='sequence_input')\n",
    "\n",
    "    # Concatenate LSTM output with sequence-level features\n",
    "    concatenated = Concatenate()([lstm0_out, sequence_input])\n",
    "\n",
    "    # Dense layer(s) after concatenation\n",
    "    dense0_out = Dense(lstm_units, activation='relu', kernel_regularizer=l2(0.02))(concatenated)\n",
    "    dense0_out = Dropout(dropout_rate)(dense0_out)\n",
    "    #dense1_out = Dense(int(lstm_units/2), activation='relu')(dense0_out)  # Additional dense layer\n",
    "    #dense1_out = Dropout(dropout_rate)(dense1_out)\n",
    "    #dense_out = Dense(int(lstm_units/4), activation='relu')(dense1_out)  # Additional dense layer\n",
    "    #dense_out = Dropout(dropout_rate)(dense_out)\n",
    "    \n",
    "    # Output layer\n",
    "    output = Dense(num_classes, activation='softmax')(dense0_out)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[event_input, sequence_input], outputs=output)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer= optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb1a393d-8009-4263-a6eb-c70c1c1352e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4318 - loss: 4.6529 - val_accuracy: 0.6900 - val_loss: 2.4580\n",
      "Epoch 2/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6885 - loss: 2.1477 - val_accuracy: 0.7156 - val_loss: 1.5327\n",
      "Epoch 3/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7109 - loss: 1.4372 - val_accuracy: 0.7319 - val_loss: 1.1705\n",
      "Epoch 4/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7460 - loss: 1.0865 - val_accuracy: 0.7273 - val_loss: 0.9935\n",
      "Epoch 5/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7509 - loss: 0.9184 - val_accuracy: 0.7319 - val_loss: 0.9173\n",
      "Epoch 6/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7333 - loss: 0.8681 - val_accuracy: 0.7226 - val_loss: 0.8793\n",
      "Epoch 7/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7561 - loss: 0.8180 - val_accuracy: 0.7319 - val_loss: 0.8336\n",
      "Epoch 8/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7268 - loss: 0.8201 - val_accuracy: 0.7319 - val_loss: 0.7957\n",
      "Epoch 9/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7669 - loss: 0.7186 - val_accuracy: 0.7669 - val_loss: 0.7279\n",
      "Epoch 10/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7769 - loss: 0.7097 - val_accuracy: 0.7179 - val_loss: 0.7740\n",
      "Epoch 11/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7718 - loss: 0.6878 - val_accuracy: 0.7739 - val_loss: 0.6637\n",
      "Epoch 12/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7994 - loss: 0.6238 - val_accuracy: 0.7249 - val_loss: 1.0767\n",
      "Epoch 13/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7268 - loss: 0.8537 - val_accuracy: 0.7762 - val_loss: 0.6896\n",
      "Epoch 14/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8064 - loss: 0.6409 - val_accuracy: 0.7995 - val_loss: 0.6488\n",
      "Epoch 15/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7980 - loss: 0.6516 - val_accuracy: 0.8135 - val_loss: 0.6185\n",
      "Epoch 16/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8119 - loss: 0.6037 - val_accuracy: 0.8345 - val_loss: 0.5905\n",
      "Epoch 17/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8372 - loss: 0.5501 - val_accuracy: 0.8322 - val_loss: 0.6122\n",
      "Epoch 18/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8294 - loss: 0.5483 - val_accuracy: 0.8322 - val_loss: 0.5690\n",
      "Epoch 19/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8131 - loss: 0.5488 - val_accuracy: 0.8112 - val_loss: 0.5666\n",
      "Epoch 20/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8537 - loss: 0.4924 - val_accuracy: 0.8228 - val_loss: 0.5473\n",
      "Epoch 21/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8336 - loss: 0.5570 - val_accuracy: 0.7156 - val_loss: 0.7544\n",
      "Epoch 22/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7917 - loss: 0.6316 - val_accuracy: 0.8345 - val_loss: 0.5456\n",
      "Epoch 23/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8352 - loss: 0.5272 - val_accuracy: 0.8322 - val_loss: 0.5390\n",
      "Epoch 24/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8355 - loss: 0.5275 - val_accuracy: 0.7809 - val_loss: 0.5574\n",
      "Epoch 25/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8397 - loss: 0.4941 - val_accuracy: 0.8345 - val_loss: 0.5276\n",
      "Epoch 26/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8463 - loss: 0.4865 - val_accuracy: 0.8275 - val_loss: 0.5237\n",
      "Epoch 27/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8287 - loss: 0.5256 - val_accuracy: 0.8345 - val_loss: 0.5149\n",
      "Epoch 28/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8364 - loss: 0.5235 - val_accuracy: 0.8368 - val_loss: 0.5013\n",
      "Epoch 29/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8312 - loss: 0.5083 - val_accuracy: 0.8112 - val_loss: 0.5387\n",
      "Epoch 30/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8326 - loss: 0.5160 - val_accuracy: 0.8275 - val_loss: 0.5375\n",
      "Epoch 31/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8398 - loss: 0.4946 - val_accuracy: 0.8392 - val_loss: 0.4907\n",
      "Epoch 32/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8438 - loss: 0.4716 - val_accuracy: 0.8345 - val_loss: 0.4904\n",
      "Epoch 33/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8509 - loss: 0.4662 - val_accuracy: 0.8415 - val_loss: 0.4812\n",
      "Epoch 34/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8385 - loss: 0.4784 - val_accuracy: 0.8322 - val_loss: 0.5087\n",
      "Epoch 35/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8202 - loss: 0.5459 - val_accuracy: 0.8275 - val_loss: 0.5066\n",
      "Epoch 36/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8594 - loss: 0.4742 - val_accuracy: 0.8298 - val_loss: 0.5118\n",
      "Epoch 37/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8353 - loss: 0.4702 - val_accuracy: 0.8345 - val_loss: 0.4853\n",
      "Epoch 38/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8407 - loss: 0.4689 - val_accuracy: 0.8345 - val_loss: 0.4780\n",
      "Epoch 39/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8232 - loss: 0.4973 - val_accuracy: 0.8345 - val_loss: 0.4764\n",
      "Epoch 40/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8468 - loss: 0.4733 - val_accuracy: 0.8415 - val_loss: 0.4735\n",
      "Epoch 41/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8387 - loss: 0.4675 - val_accuracy: 0.8415 - val_loss: 0.4808\n",
      "Epoch 42/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8296 - loss: 0.5111 - val_accuracy: 0.8368 - val_loss: 0.5308\n",
      "Epoch 43/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8327 - loss: 0.4995 - val_accuracy: 0.8392 - val_loss: 0.4715\n",
      "Epoch 44/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8305 - loss: 0.4783 - val_accuracy: 0.8392 - val_loss: 0.5148\n",
      "Epoch 45/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8345 - loss: 0.4831 - val_accuracy: 0.8415 - val_loss: 0.4632\n",
      "Epoch 46/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8489 - loss: 0.4450 - val_accuracy: 0.8368 - val_loss: 0.4912\n",
      "Epoch 47/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8397 - loss: 0.4755 - val_accuracy: 0.8415 - val_loss: 0.4671\n",
      "Epoch 48/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8437 - loss: 0.4538 - val_accuracy: 0.8415 - val_loss: 0.4608\n",
      "Epoch 49/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8349 - loss: 0.4486 - val_accuracy: 0.8345 - val_loss: 0.4691\n",
      "Epoch 50/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8344 - loss: 0.4576 - val_accuracy: 0.8392 - val_loss: 0.4558\n",
      "Epoch 51/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8626 - loss: 0.4249 - val_accuracy: 0.8345 - val_loss: 0.4585\n",
      "Epoch 52/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8619 - loss: 0.4216 - val_accuracy: 0.8415 - val_loss: 0.4497\n",
      "Epoch 53/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8192 - loss: 0.5592 - val_accuracy: 0.8368 - val_loss: 0.4820\n",
      "Epoch 54/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8235 - loss: 0.5117 - val_accuracy: 0.7832 - val_loss: 0.6619\n",
      "Epoch 55/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8282 - loss: 0.5014 - val_accuracy: 0.8392 - val_loss: 0.4811\n",
      "Epoch 56/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8428 - loss: 0.4678 - val_accuracy: 0.7786 - val_loss: 0.5330\n",
      "Epoch 57/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8215 - loss: 0.4792 - val_accuracy: 0.8368 - val_loss: 0.4661\n",
      "Epoch 58/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8462 - loss: 0.4388 - val_accuracy: 0.8345 - val_loss: 0.4658\n",
      "Epoch 59/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8421 - loss: 0.4512 - val_accuracy: 0.8415 - val_loss: 0.4539\n",
      "Epoch 60/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8499 - loss: 0.4240 - val_accuracy: 0.8159 - val_loss: 0.5258\n",
      "Epoch 61/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8100 - loss: 0.5243 - val_accuracy: 0.8392 - val_loss: 0.4912\n",
      "Epoch 62/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8417 - loss: 0.4836 - val_accuracy: 0.8415 - val_loss: 0.4630\n",
      "Epoch 63/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8308 - loss: 0.4707 - val_accuracy: 0.8415 - val_loss: 0.4760\n",
      "Epoch 64/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8409 - loss: 0.4475 - val_accuracy: 0.8415 - val_loss: 0.4583\n",
      "Epoch 65/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8345 - loss: 0.4591 - val_accuracy: 0.8345 - val_loss: 0.4753\n",
      "Epoch 66/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8478 - loss: 0.4444 - val_accuracy: 0.8415 - val_loss: 0.4510\n",
      "Epoch 67/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8389 - loss: 0.4437 - val_accuracy: 0.8392 - val_loss: 0.4595\n",
      "Epoch 68/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8569 - loss: 0.4214 - val_accuracy: 0.8415 - val_loss: 0.4493\n",
      "Epoch 69/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8262 - loss: 0.4710 - val_accuracy: 0.8345 - val_loss: 0.4534\n",
      "Epoch 70/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8513 - loss: 0.4221 - val_accuracy: 0.8368 - val_loss: 0.4595\n",
      "Epoch 71/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8437 - loss: 0.4392 - val_accuracy: 0.7925 - val_loss: 0.5982\n",
      "Epoch 72/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8092 - loss: 0.5190 - val_accuracy: 0.8415 - val_loss: 0.4845\n",
      "Epoch 73/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8429 - loss: 0.4571 - val_accuracy: 0.8415 - val_loss: 0.4613\n",
      "Epoch 74/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8525 - loss: 0.4294 - val_accuracy: 0.8415 - val_loss: 0.4490\n",
      "Epoch 75/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8389 - loss: 0.4570 - val_accuracy: 0.8438 - val_loss: 0.4492\n",
      "Epoch 76/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8360 - loss: 0.4484 - val_accuracy: 0.8368 - val_loss: 0.4970\n",
      "Epoch 77/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8611 - loss: 0.4244 - val_accuracy: 0.8415 - val_loss: 0.4422\n",
      "Epoch 78/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8404 - loss: 0.4504 - val_accuracy: 0.8415 - val_loss: 0.4495\n",
      "Epoch 79/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8493 - loss: 0.4072 - val_accuracy: 0.8415 - val_loss: 0.4441\n",
      "Epoch 80/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8538 - loss: 0.4288 - val_accuracy: 0.8275 - val_loss: 0.4772\n",
      "Epoch 81/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8509 - loss: 0.4398 - val_accuracy: 0.8345 - val_loss: 0.4611\n",
      "Epoch 82/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8552 - loss: 0.4236 - val_accuracy: 0.8438 - val_loss: 0.4507\n",
      "Epoch 83/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8277 - loss: 0.4608 - val_accuracy: 0.7949 - val_loss: 0.6297\n",
      "Epoch 84/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8331 - loss: 0.4896 - val_accuracy: 0.8415 - val_loss: 0.4637\n",
      "Epoch 85/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8419 - loss: 0.4461 - val_accuracy: 0.8392 - val_loss: 0.4431\n",
      "Epoch 86/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8367 - loss: 0.4455 - val_accuracy: 0.8415 - val_loss: 0.4371\n",
      "Epoch 87/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8522 - loss: 0.4174 - val_accuracy: 0.8415 - val_loss: 0.4489\n",
      "Epoch 88/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8444 - loss: 0.4308 - val_accuracy: 0.8322 - val_loss: 0.4678\n",
      "Epoch 89/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8204 - loss: 0.5162 - val_accuracy: 0.8368 - val_loss: 0.4951\n",
      "Epoch 90/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8411 - loss: 0.4644 - val_accuracy: 0.7646 - val_loss: 0.6015\n",
      "Epoch 91/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8376 - loss: 0.4778 - val_accuracy: 0.8368 - val_loss: 0.4725\n",
      "Epoch 92/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8425 - loss: 0.4509 - val_accuracy: 0.8368 - val_loss: 0.4472\n",
      "Epoch 93/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8404 - loss: 0.4469 - val_accuracy: 0.8415 - val_loss: 0.4412\n",
      "Epoch 94/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8490 - loss: 0.4285 - val_accuracy: 0.8392 - val_loss: 0.4522\n",
      "Epoch 95/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8300 - loss: 0.4531 - val_accuracy: 0.8228 - val_loss: 0.4855\n",
      "Epoch 96/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8314 - loss: 0.4555 - val_accuracy: 0.8415 - val_loss: 0.4433\n",
      "Epoch 97/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8391 - loss: 0.4412 - val_accuracy: 0.8415 - val_loss: 0.4423\n",
      "Epoch 98/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8493 - loss: 0.4275 - val_accuracy: 0.8135 - val_loss: 0.4637\n",
      "Epoch 99/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8544 - loss: 0.4208 - val_accuracy: 0.8368 - val_loss: 0.4589\n",
      "Epoch 100/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8545 - loss: 0.4169 - val_accuracy: 0.8415 - val_loss: 0.4391\n",
      "Epoch 101/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8178 - loss: 0.4584 - val_accuracy: 0.8345 - val_loss: 0.4543\n",
      "Epoch 102/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8467 - loss: 0.4271 - val_accuracy: 0.8415 - val_loss: 0.4493\n",
      "Epoch 103/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8425 - loss: 0.4248 - val_accuracy: 0.8392 - val_loss: 0.4382\n",
      "Epoch 104/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8538 - loss: 0.4201 - val_accuracy: 0.8345 - val_loss: 0.4349\n",
      "Epoch 105/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8243 - loss: 0.4526 - val_accuracy: 0.8368 - val_loss: 0.4610\n",
      "Epoch 106/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8477 - loss: 0.4323 - val_accuracy: 0.8415 - val_loss: 0.4516\n",
      "Epoch 107/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8403 - loss: 0.4369 - val_accuracy: 0.8415 - val_loss: 0.4400\n",
      "Epoch 108/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8537 - loss: 0.4124 - val_accuracy: 0.8415 - val_loss: 0.4475\n",
      "Epoch 109/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8459 - loss: 0.4182 - val_accuracy: 0.8345 - val_loss: 0.4441\n",
      "Epoch 110/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8393 - loss: 0.4313 - val_accuracy: 0.8438 - val_loss: 0.4579\n",
      "Epoch 111/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8323 - loss: 0.4437 - val_accuracy: 0.8438 - val_loss: 0.4350\n",
      "Epoch 112/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8532 - loss: 0.4208 - val_accuracy: 0.8275 - val_loss: 0.4793\n",
      "Epoch 113/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8337 - loss: 0.4371 - val_accuracy: 0.8345 - val_loss: 0.4520\n",
      "Epoch 114/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.4287 - val_accuracy: 0.8438 - val_loss: 0.4505\n",
      "Epoch 115/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8489 - loss: 0.4202 - val_accuracy: 0.8392 - val_loss: 0.4391\n",
      "Epoch 116/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8376 - loss: 0.4310 - val_accuracy: 0.8345 - val_loss: 0.4367\n",
      "Epoch 117/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8391 - loss: 0.4247 - val_accuracy: 0.8415 - val_loss: 0.4383\n",
      "Epoch 118/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8388 - loss: 0.4373 - val_accuracy: 0.8345 - val_loss: 0.4791\n",
      "Epoch 119/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8461 - loss: 0.4388 - val_accuracy: 0.8415 - val_loss: 0.4428\n",
      "Epoch 120/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8541 - loss: 0.4106 - val_accuracy: 0.8182 - val_loss: 0.4896\n",
      "Epoch 121/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 0.4971 - val_accuracy: 0.8275 - val_loss: 0.5153\n",
      "Epoch 122/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8465 - loss: 0.5040 - val_accuracy: 0.8392 - val_loss: 0.4765\n",
      "Epoch 123/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8533 - loss: 0.4284 - val_accuracy: 0.8415 - val_loss: 0.4536\n",
      "Epoch 124/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8372 - loss: 0.4449 - val_accuracy: 0.8392 - val_loss: 0.4422\n",
      "Epoch 125/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8434 - loss: 0.4263 - val_accuracy: 0.8415 - val_loss: 0.4491\n",
      "Epoch 126/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8478 - loss: 0.4178 - val_accuracy: 0.8368 - val_loss: 0.4471\n",
      "Epoch 127/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8488 - loss: 0.4201 - val_accuracy: 0.8415 - val_loss: 0.4431\n",
      "Epoch 128/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8409 - loss: 0.4283 - val_accuracy: 0.8345 - val_loss: 0.4414\n",
      "Epoch 129/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8537 - loss: 0.4161 - val_accuracy: 0.8019 - val_loss: 0.4848\n",
      "Epoch 130/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8321 - loss: 0.4341 - val_accuracy: 0.8392 - val_loss: 0.4361\n",
      "Epoch 131/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8479 - loss: 0.4083 - val_accuracy: 0.8415 - val_loss: 0.4415\n",
      "Epoch 132/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8401 - loss: 0.4256 - val_accuracy: 0.8368 - val_loss: 0.4423\n",
      "Epoch 133/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8399 - loss: 0.4165 - val_accuracy: 0.8415 - val_loss: 0.4354\n",
      "Epoch 134/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8431 - loss: 0.4252 - val_accuracy: 0.8228 - val_loss: 0.4969\n",
      "Epoch 135/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8485 - loss: 0.4182 - val_accuracy: 0.8392 - val_loss: 0.4515\n",
      "Epoch 136/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8344 - loss: 0.4427 - val_accuracy: 0.8415 - val_loss: 0.4537\n",
      "Epoch 137/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8445 - loss: 0.4191 - val_accuracy: 0.8415 - val_loss: 0.4311\n",
      "Epoch 138/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8519 - loss: 0.4150 - val_accuracy: 0.8368 - val_loss: 0.4572\n",
      "Epoch 139/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8549 - loss: 0.4009 - val_accuracy: 0.8415 - val_loss: 0.4292\n",
      "Epoch 140/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8602 - loss: 0.4061 - val_accuracy: 0.7949 - val_loss: 0.5814\n",
      "Epoch 141/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8171 - loss: 0.5428 - val_accuracy: 0.8345 - val_loss: 0.4882\n",
      "Epoch 142/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 0.4510 - val_accuracy: 0.8415 - val_loss: 0.4533\n",
      "Epoch 143/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8486 - loss: 0.4217 - val_accuracy: 0.8392 - val_loss: 0.4635\n",
      "Epoch 144/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8533 - loss: 0.4089 - val_accuracy: 0.8438 - val_loss: 0.4400\n",
      "Epoch 145/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8459 - loss: 0.4205 - val_accuracy: 0.8368 - val_loss: 0.4461\n",
      "Epoch 146/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8400 - loss: 0.4375 - val_accuracy: 0.8392 - val_loss: 0.4628\n",
      "Epoch 147/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8513 - loss: 0.4062 - val_accuracy: 0.8298 - val_loss: 0.4700\n",
      "Epoch 148/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8576 - loss: 0.4114 - val_accuracy: 0.8415 - val_loss: 0.4417\n",
      "Epoch 149/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8451 - loss: 0.4231 - val_accuracy: 0.8415 - val_loss: 0.4384\n",
      "Epoch 150/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8609 - loss: 0.3997 - val_accuracy: 0.8392 - val_loss: 0.4364\n",
      "Epoch 151/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8487 - loss: 0.4081 - val_accuracy: 0.8415 - val_loss: 0.4360\n",
      "Epoch 152/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 0.4125 - val_accuracy: 0.8415 - val_loss: 0.4600\n",
      "Epoch 153/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8391 - loss: 0.4244 - val_accuracy: 0.8368 - val_loss: 0.4635\n",
      "Epoch 154/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8575 - loss: 0.3966 - val_accuracy: 0.8415 - val_loss: 0.4552\n",
      "Epoch 155/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8430 - loss: 0.4197 - val_accuracy: 0.8322 - val_loss: 0.4577\n",
      "Epoch 156/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8509 - loss: 0.4256 - val_accuracy: 0.8415 - val_loss: 0.4377\n",
      "Epoch 157/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8455 - loss: 0.4154 - val_accuracy: 0.8368 - val_loss: 0.4475\n",
      "Epoch 158/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8363 - loss: 0.4313 - val_accuracy: 0.8228 - val_loss: 0.4531\n",
      "Epoch 159/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8360 - loss: 0.4252 - val_accuracy: 0.8415 - val_loss: 0.4471\n",
      "Epoch 160/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8420 - loss: 0.4226 - val_accuracy: 0.8368 - val_loss: 0.4629\n",
      "Epoch 161/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8424 - loss: 0.4344 - val_accuracy: 0.7296 - val_loss: 0.9069\n",
      "Epoch 162/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7616 - loss: 0.7602 - val_accuracy: 0.8228 - val_loss: 0.5576\n",
      "Epoch 163/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8401 - loss: 0.4943 - val_accuracy: 0.8415 - val_loss: 0.4677\n",
      "Epoch 164/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8433 - loss: 0.4435 - val_accuracy: 0.8438 - val_loss: 0.4760\n",
      "Epoch 165/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8383 - loss: 0.4653 - val_accuracy: 0.8415 - val_loss: 0.4620\n",
      "Epoch 166/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8550 - loss: 0.4118 - val_accuracy: 0.8415 - val_loss: 0.4621\n",
      "Epoch 167/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8467 - loss: 0.4417 - val_accuracy: 0.8438 - val_loss: 0.4558\n",
      "Epoch 168/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8431 - loss: 0.4507 - val_accuracy: 0.8462 - val_loss: 0.4583\n",
      "Epoch 169/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8430 - loss: 0.4246 - val_accuracy: 0.8392 - val_loss: 0.4487\n",
      "Epoch 170/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8384 - loss: 0.4388 - val_accuracy: 0.8438 - val_loss: 0.4362\n",
      "Epoch 171/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8457 - loss: 0.4199 - val_accuracy: 0.8438 - val_loss: 0.4461\n",
      "Epoch 172/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8552 - loss: 0.4074 - val_accuracy: 0.8415 - val_loss: 0.4388\n",
      "Epoch 173/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8345 - loss: 0.4258 - val_accuracy: 0.8438 - val_loss: 0.4376\n",
      "Epoch 174/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8447 - loss: 0.4188 - val_accuracy: 0.8392 - val_loss: 0.4517\n",
      "Epoch 175/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8523 - loss: 0.4167 - val_accuracy: 0.8438 - val_loss: 0.4545\n",
      "Epoch 176/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8596 - loss: 0.3907 - val_accuracy: 0.8415 - val_loss: 0.4342\n",
      "Epoch 177/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8405 - loss: 0.4226 - val_accuracy: 0.8392 - val_loss: 0.4373\n",
      "Epoch 178/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8477 - loss: 0.4055 - val_accuracy: 0.8415 - val_loss: 0.4425\n",
      "Epoch 179/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8454 - loss: 0.4087 - val_accuracy: 0.8462 - val_loss: 0.4432\n",
      "Epoch 180/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8399 - loss: 0.4203 - val_accuracy: 0.8135 - val_loss: 0.5039\n",
      "Epoch 181/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8440 - loss: 0.4372 - val_accuracy: 0.8345 - val_loss: 0.4471\n",
      "Epoch 182/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8378 - loss: 0.4354 - val_accuracy: 0.8392 - val_loss: 0.4378\n",
      "Epoch 183/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8442 - loss: 0.4125 - val_accuracy: 0.8462 - val_loss: 0.4362\n",
      "Epoch 184/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8622 - loss: 0.3907 - val_accuracy: 0.8438 - val_loss: 0.4356\n",
      "Epoch 185/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8343 - loss: 0.4312 - val_accuracy: 0.8392 - val_loss: 0.4600\n",
      "Epoch 186/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8489 - loss: 0.4145 - val_accuracy: 0.8368 - val_loss: 0.4817\n",
      "Epoch 187/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8531 - loss: 0.4484 - val_accuracy: 0.8392 - val_loss: 0.4769\n",
      "Epoch 188/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8331 - loss: 0.4382 - val_accuracy: 0.8415 - val_loss: 0.4360\n",
      "Epoch 189/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8515 - loss: 0.4275 - val_accuracy: 0.8415 - val_loss: 0.4350\n",
      "Epoch 190/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8613 - loss: 0.3909 - val_accuracy: 0.8438 - val_loss: 0.4312\n",
      "Epoch 191/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8556 - loss: 0.3984 - val_accuracy: 0.8392 - val_loss: 0.4373\n",
      "Epoch 192/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8525 - loss: 0.4004 - val_accuracy: 0.8392 - val_loss: 0.4504\n",
      "Epoch 193/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8466 - loss: 0.4031 - val_accuracy: 0.8415 - val_loss: 0.4441\n",
      "Epoch 194/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8324 - loss: 0.4255 - val_accuracy: 0.8415 - val_loss: 0.4332\n",
      "Epoch 195/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8422 - loss: 0.4177 - val_accuracy: 0.8415 - val_loss: 0.4302\n",
      "Epoch 196/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8574 - loss: 0.4032 - val_accuracy: 0.8392 - val_loss: 0.4618\n",
      "Epoch 197/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8551 - loss: 0.4212 - val_accuracy: 0.8368 - val_loss: 0.4343\n",
      "Epoch 198/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8534 - loss: 0.4178 - val_accuracy: 0.8438 - val_loss: 0.4354\n",
      "Epoch 199/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8425 - loss: 0.4141 - val_accuracy: 0.8462 - val_loss: 0.4320\n",
      "Epoch 200/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8439 - loss: 0.4229 - val_accuracy: 0.8415 - val_loss: 0.4355\n",
      "Epoch 201/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8499 - loss: 0.4167 - val_accuracy: 0.8438 - val_loss: 0.4343\n",
      "Epoch 202/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8447 - loss: 0.4162 - val_accuracy: 0.8415 - val_loss: 0.4637\n",
      "Epoch 203/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8441 - loss: 0.4225 - val_accuracy: 0.8415 - val_loss: 0.4382\n",
      "Epoch 204/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8433 - loss: 0.4084 - val_accuracy: 0.8392 - val_loss: 0.4465\n",
      "Epoch 205/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8413 - loss: 0.4187 - val_accuracy: 0.8485 - val_loss: 0.4288\n",
      "Epoch 206/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8501 - loss: 0.3992 - val_accuracy: 0.8415 - val_loss: 0.4389\n",
      "Epoch 207/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8516 - loss: 0.4049 - val_accuracy: 0.8438 - val_loss: 0.4266\n",
      "Epoch 208/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8077 - loss: 0.4484 - val_accuracy: 0.8392 - val_loss: 0.4374\n",
      "Epoch 209/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8537 - loss: 0.4042 - val_accuracy: 0.8392 - val_loss: 0.4335\n",
      "Epoch 210/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8354 - loss: 0.4604 - val_accuracy: 0.8345 - val_loss: 0.4775\n",
      "Epoch 211/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8442 - loss: 0.4340 - val_accuracy: 0.8392 - val_loss: 0.4480\n",
      "Epoch 212/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8375 - loss: 0.4193 - val_accuracy: 0.8438 - val_loss: 0.4316\n",
      "Epoch 213/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8564 - loss: 0.3884 - val_accuracy: 0.8368 - val_loss: 0.4516\n",
      "Epoch 214/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8471 - loss: 0.4181 - val_accuracy: 0.8392 - val_loss: 0.4372\n",
      "Epoch 215/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8362 - loss: 0.4090 - val_accuracy: 0.8415 - val_loss: 0.4382\n",
      "Epoch 216/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8517 - loss: 0.4040 - val_accuracy: 0.8508 - val_loss: 0.4463\n",
      "Epoch 217/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8413 - loss: 0.4342 - val_accuracy: 0.8392 - val_loss: 0.4370\n",
      "Epoch 218/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8398 - loss: 0.4072 - val_accuracy: 0.8392 - val_loss: 0.4277\n",
      "Epoch 219/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8322 - loss: 0.4194 - val_accuracy: 0.8438 - val_loss: 0.4424\n",
      "Epoch 220/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8391 - loss: 0.4141 - val_accuracy: 0.8438 - val_loss: 0.4339\n",
      "Epoch 221/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8386 - loss: 0.4209 - val_accuracy: 0.8438 - val_loss: 0.4602\n",
      "Epoch 222/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8466 - loss: 0.4056 - val_accuracy: 0.8415 - val_loss: 0.4490\n",
      "Epoch 223/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8400 - loss: 0.4380 - val_accuracy: 0.8462 - val_loss: 0.4697\n",
      "Epoch 224/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8331 - loss: 0.4346 - val_accuracy: 0.8415 - val_loss: 0.4779\n",
      "Epoch 225/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8268 - loss: 0.4415 - val_accuracy: 0.8415 - val_loss: 0.4482\n",
      "Epoch 226/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8592 - loss: 0.3838 - val_accuracy: 0.8392 - val_loss: 0.4420\n",
      "Epoch 227/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8560 - loss: 0.3855 - val_accuracy: 0.8345 - val_loss: 0.4530\n",
      "Epoch 228/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8494 - loss: 0.4034 - val_accuracy: 0.8415 - val_loss: 0.4443\n",
      "Epoch 229/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8246 - loss: 0.4339 - val_accuracy: 0.8415 - val_loss: 0.4358\n",
      "Epoch 230/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8430 - loss: 0.4049 - val_accuracy: 0.8415 - val_loss: 0.4350\n",
      "Epoch 231/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8526 - loss: 0.3923 - val_accuracy: 0.8438 - val_loss: 0.4325\n",
      "Epoch 232/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8279 - loss: 0.4266 - val_accuracy: 0.8415 - val_loss: 0.4415\n",
      "Epoch 233/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8410 - loss: 0.4043 - val_accuracy: 0.8345 - val_loss: 0.4694\n",
      "Epoch 234/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8561 - loss: 0.3928 - val_accuracy: 0.8438 - val_loss: 0.4591\n",
      "Epoch 235/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8447 - loss: 0.4083 - val_accuracy: 0.8415 - val_loss: 0.4535\n",
      "Epoch 236/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8514 - loss: 0.4006 - val_accuracy: 0.8415 - val_loss: 0.4433\n",
      "Epoch 237/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8471 - loss: 0.4095 - val_accuracy: 0.8392 - val_loss: 0.4395\n",
      "Epoch 238/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8491 - loss: 0.4045 - val_accuracy: 0.8462 - val_loss: 0.4340\n",
      "Epoch 239/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8528 - loss: 0.3870 - val_accuracy: 0.8368 - val_loss: 0.4334\n",
      "Epoch 240/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8349 - loss: 0.4289 - val_accuracy: 0.8438 - val_loss: 0.4369\n",
      "Epoch 241/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8458 - loss: 0.4020 - val_accuracy: 0.8508 - val_loss: 0.4469\n",
      "Epoch 242/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8524 - loss: 0.4062 - val_accuracy: 0.8438 - val_loss: 0.4262\n",
      "Epoch 243/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8492 - loss: 0.4065 - val_accuracy: 0.8392 - val_loss: 0.4474\n",
      "Epoch 244/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8397 - loss: 0.4295 - val_accuracy: 0.8415 - val_loss: 0.4371\n",
      "Epoch 245/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8390 - loss: 0.4113 - val_accuracy: 0.8438 - val_loss: 0.4306\n",
      "Epoch 246/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8513 - loss: 0.3944 - val_accuracy: 0.8415 - val_loss: 0.4301\n",
      "Epoch 247/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8454 - loss: 0.3938 - val_accuracy: 0.8392 - val_loss: 0.4457\n",
      "Epoch 248/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8313 - loss: 0.4260 - val_accuracy: 0.8415 - val_loss: 0.4393\n",
      "Epoch 249/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8623 - loss: 0.3797 - val_accuracy: 0.8438 - val_loss: 0.4253\n",
      "Epoch 250/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8454 - loss: 0.4032 - val_accuracy: 0.8392 - val_loss: 0.4439\n",
      "Epoch 251/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8462 - loss: 0.3993 - val_accuracy: 0.8438 - val_loss: 0.4336\n",
      "Epoch 252/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8432 - loss: 0.4051 - val_accuracy: 0.8462 - val_loss: 0.4394\n",
      "Epoch 253/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8541 - loss: 0.3896 - val_accuracy: 0.8438 - val_loss: 0.4308\n",
      "Epoch 254/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8399 - loss: 0.4044 - val_accuracy: 0.8462 - val_loss: 0.4383\n",
      "Epoch 255/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8409 - loss: 0.4120 - val_accuracy: 0.6597 - val_loss: 0.8994\n",
      "Epoch 256/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8139 - loss: 0.6158 - val_accuracy: 0.8042 - val_loss: 0.6591\n",
      "Epoch 257/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8021 - loss: 0.5899 - val_accuracy: 0.8508 - val_loss: 0.4820\n",
      "Epoch 258/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8354 - loss: 0.4632 - val_accuracy: 0.8438 - val_loss: 0.5005\n",
      "Epoch 259/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8504 - loss: 0.4166 - val_accuracy: 0.8392 - val_loss: 0.4483\n",
      "Epoch 260/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8661 - loss: 0.3893 - val_accuracy: 0.8415 - val_loss: 0.4495\n",
      "Epoch 261/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8611 - loss: 0.3956 - val_accuracy: 0.8345 - val_loss: 0.4739\n",
      "Epoch 262/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8587 - loss: 0.3938 - val_accuracy: 0.8392 - val_loss: 0.4856\n",
      "Epoch 263/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8432 - loss: 0.4088 - val_accuracy: 0.8438 - val_loss: 0.4359\n",
      "Epoch 264/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8549 - loss: 0.3874 - val_accuracy: 0.8485 - val_loss: 0.4357\n",
      "Epoch 265/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8456 - loss: 0.4116 - val_accuracy: 0.8392 - val_loss: 0.4524\n",
      "Epoch 266/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8484 - loss: 0.3890 - val_accuracy: 0.8392 - val_loss: 0.4412\n",
      "Epoch 267/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8602 - loss: 0.3902 - val_accuracy: 0.8508 - val_loss: 0.4238\n",
      "Epoch 268/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8680 - loss: 0.3766 - val_accuracy: 0.8415 - val_loss: 0.4480\n",
      "Epoch 269/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8328 - loss: 0.4232 - val_accuracy: 0.8485 - val_loss: 0.4305\n",
      "Epoch 270/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8653 - loss: 0.3879 - val_accuracy: 0.8508 - val_loss: 0.4289\n",
      "Epoch 271/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8415 - loss: 0.3967 - val_accuracy: 0.8485 - val_loss: 0.4245\n",
      "Epoch 272/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8558 - loss: 0.3812 - val_accuracy: 0.8462 - val_loss: 0.4467\n",
      "Epoch 273/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8303 - loss: 0.4268 - val_accuracy: 0.8438 - val_loss: 0.4296\n",
      "Epoch 274/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8501 - loss: 0.3848 - val_accuracy: 0.8462 - val_loss: 0.4254\n",
      "Epoch 275/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8526 - loss: 0.3955 - val_accuracy: 0.8438 - val_loss: 0.4263\n",
      "Epoch 276/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8469 - loss: 0.3975 - val_accuracy: 0.8438 - val_loss: 0.4625\n",
      "Epoch 277/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8328 - loss: 0.4180 - val_accuracy: 0.8438 - val_loss: 0.4360\n",
      "Epoch 278/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8527 - loss: 0.3887 - val_accuracy: 0.8531 - val_loss: 0.4265\n",
      "Epoch 279/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8428 - loss: 0.4025 - val_accuracy: 0.8415 - val_loss: 0.4664\n",
      "Epoch 280/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8547 - loss: 0.3855 - val_accuracy: 0.8485 - val_loss: 0.4285\n",
      "Epoch 281/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8311 - loss: 0.4194 - val_accuracy: 0.8415 - val_loss: 0.4704\n",
      "Epoch 282/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8453 - loss: 0.4100 - val_accuracy: 0.8438 - val_loss: 0.4400\n",
      "Epoch 283/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8427 - loss: 0.4143 - val_accuracy: 0.8415 - val_loss: 0.4664\n",
      "Epoch 284/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8512 - loss: 0.4099 - val_accuracy: 0.8392 - val_loss: 0.4768\n",
      "Epoch 285/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8573 - loss: 0.3893 - val_accuracy: 0.8531 - val_loss: 0.4284\n",
      "Epoch 286/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8559 - loss: 0.3857 - val_accuracy: 0.8345 - val_loss: 0.4514\n",
      "Epoch 287/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8655 - loss: 0.3808 - val_accuracy: 0.8508 - val_loss: 0.4322\n",
      "Epoch 288/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8515 - loss: 0.3883 - val_accuracy: 0.8555 - val_loss: 0.4266\n",
      "Epoch 289/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8485 - loss: 0.4049 - val_accuracy: 0.8415 - val_loss: 0.4597\n",
      "Epoch 290/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8469 - loss: 0.4130 - val_accuracy: 0.8531 - val_loss: 0.4369\n",
      "Epoch 291/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8422 - loss: 0.4044 - val_accuracy: 0.8368 - val_loss: 0.4495\n",
      "Epoch 292/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8553 - loss: 0.3800 - val_accuracy: 0.8508 - val_loss: 0.4362\n",
      "Epoch 293/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8579 - loss: 0.3953 - val_accuracy: 0.8555 - val_loss: 0.4269\n",
      "Epoch 294/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8459 - loss: 0.4062 - val_accuracy: 0.8531 - val_loss: 0.4376\n",
      "Epoch 295/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8564 - loss: 0.3883 - val_accuracy: 0.8392 - val_loss: 0.4405\n",
      "Epoch 296/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8539 - loss: 0.3783 - val_accuracy: 0.8438 - val_loss: 0.4468\n",
      "Epoch 297/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8552 - loss: 0.3876 - val_accuracy: 0.8508 - val_loss: 0.4200\n",
      "Epoch 298/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8496 - loss: 0.3917 - val_accuracy: 0.8438 - val_loss: 0.4444\n",
      "Epoch 299/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8455 - loss: 0.4073 - val_accuracy: 0.8438 - val_loss: 0.4368\n",
      "Epoch 300/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8586 - loss: 0.3741 - val_accuracy: 0.8392 - val_loss: 0.4542\n"
     ]
    }
   ],
   "source": [
    "model = create_combined_lstm_model(event_input_shape, num_sequence_features, num_classes, lstm_units=128, dropout_rate=0.2)\n",
    "history = model.fit([event_encode, sequence_encode],y_encode, epochs=300, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58a68903-e070-4cd5-a7bd-8fe5e7d3c2dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_training_history(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b40ae-87d6-4a18-b778-4cc3697cb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history_smooth(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dcdb5a-eda0-47cd-b54c-d91b28747d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
